{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cc263e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbconvert[qtpdf] in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (7.3.0)\n",
      "Requirement already satisfied: jinja2>=3.0 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (3.1.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (0.7.3)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (6.2.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (0.2.2)\n",
      "Requirement already satisfied: defusedxml in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (0.7.1)\n",
      "Requirement already satisfied: packaging in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (23.0)\n",
      "Requirement already satisfied: tinycss2 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (1.2.1)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (5.3.0)\n",
      "Requirement already satisfied: traitlets>=5.0 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (5.9.0)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (2.0.5)\n",
      "Requirement already satisfied: nbformat>=5.1 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (5.8.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (2.14.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (1.5.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (2.1.2)\n",
      "Requirement already satisfied: bleach in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (6.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbconvert[qtpdf]) (4.11.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from importlib-metadata>=3.6->nbconvert[qtpdf]) (3.15.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from jupyter-core>=4.7->nbconvert[qtpdf]) (3.2.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbclient>=0.5.0->nbconvert[qtpdf]) (8.1.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbformat>=5.1->nbconvert[qtpdf]) (4.17.3)\n",
      "Requirement already satisfied: fastjsonschema in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from nbformat>=5.1->nbconvert[qtpdf]) (2.16.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from beautifulsoup4->nbconvert[qtpdf]) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from bleach->nbconvert[qtpdf]) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from bleach->nbconvert[qtpdf]) (1.16.0)\n",
      "Collecting pyqtwebengine>=5.15\n",
      "  Downloading PyQtWebEngine-5.15.6-cp37-abi3-manylinux1_x86_64.whl (230 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.4/230.4 kB\u001b[0m \u001b[31m404.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert[qtpdf]) (1.3.10)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert[qtpdf]) (22.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert[qtpdf]) (5.12.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert[qtpdf]) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert[qtpdf]) (2.8.2)\n",
      "Requirement already satisfied: tornado>=6.2 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert[qtpdf]) (6.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert[qtpdf]) (25.0.2)\n",
      "Collecting PyQtWebEngine-Qt5>=5.15.0\n",
      "  Downloading PyQtWebEngine_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (67.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.5/67.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyQt5>=5.15.4 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from pyqtwebengine>=5.15->nbconvert[qtpdf]) (5.15.7)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.11 in /home/lachlan/miniconda3/envs/transformer/lib/python3.8/site-packages (from pyqtwebengine>=5.15->nbconvert[qtpdf]) (12.11.0)\n",
      "Installing collected packages: PyQtWebEngine-Qt5, pyqtwebengine\n",
      "Successfully installed PyQtWebEngine-Qt5-5.15.2 pyqtwebengine-5.15.6\n"
     ]
    }
   ],
   "source": [
    "!pip install nbconvert[qtpdf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af1aef",
   "metadata": {},
   "source": [
    "# Our First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80f209b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200], Loss: 3.4442\n",
      "Epoch [40/200], Loss: 3.2071\n",
      "Epoch [60/200], Loss: 2.9845\n",
      "Epoch [80/200], Loss: 2.7494\n",
      "Epoch [100/200], Loss: 2.5668\n",
      "Epoch [120/200], Loss: 2.3766\n",
      "Epoch [140/200], Loss: 2.1408\n",
      "Epoch [160/200], Loss: 1.9756\n",
      "Epoch [180/200], Loss: 1.8454\n",
      "Epoch [200/200], Loss: 1.6744\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Dataset\n",
    "sentences = [\n",
    "    \"The quick brown fox jumped over the lazy dog.\",\n",
    "    \"Advancements in AI have transformed the way we interact with technology.\",\n",
    "    \"Yesterday, the stock market experienced a significant decline due to geopolitical tensions.\"\n",
    "]\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized_sentences = [sentence.split() for sentence in sentences]\n",
    "\n",
    "# Create vocabulary\n",
    "word2idx = {\"[PAD]\": 0, \"[CLS]\": 1, \"[SEP]\": 2}\n",
    "for sentence in tokenized_sentences:\n",
    "    for token in sentence:\n",
    "        if token not in word2idx:\n",
    "            word2idx[token] = len(word2idx)\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "max_seq_len= 15\n",
    "\n",
    "\n",
    "# # Encode dataset\n",
    "# encoded_sentences = []\n",
    "# for sentence in tokenized_sentences:\n",
    "#     encoded_sentence = [word2idx[\"[CLS]\"]] + [word2idx[word] for word in sentence] + [word2idx[\"[SEP]\"]]\n",
    "#     encoded_sentence += [word2idx[\"[PAD]\"]] * (max_seq_len - len(encoded_sentence))\n",
    "#     encoded_sentences.append(encoded_sentence)\n",
    "# Encode dataset\n",
    "encoded_sentences = []\n",
    "for sentence in tokenized_sentences:\n",
    "    encoded_sentence = [word2idx[\"[CLS]\"]] + [word2idx[word] for word in sentence] + [word2idx[\"[SEP]\"]]\n",
    "    encoded_sentence += [word2idx[\"[PAD]\"]] * (max_seq_len - len(encoded_sentence))\n",
    "    encoded_sentences.append(encoded_sentence)\n",
    "\n",
    "# max_seq_len = max(len(sentence) for sentence in encoded_sentences)\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "d_model = 8\n",
    "nhead = 2\n",
    "num_layers = 1\n",
    "dim_feedforward = 16\n",
    "\n",
    "# # Positional Encoding\n",
    "# class PositionalEncoding(nn.Module):\n",
    "#     def __init__(self, d_model, max_seq_len):\n",
    "#         super(PositionalEncoding, self).__init__()\n",
    "#         pe = torch.zeros(max_seq_len, d_model)\n",
    "#         position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "#         div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "#         pe[:, 0::2] = torch.sin(position * div_term)\n",
    "#         pe[:, 1::2] = torch.cos(position * div_term)\n",
    "#         self.register_buffer(\"pe\", pe)\n",
    "\n",
    "#     # def forward(self, x):\n",
    "#     #     x = x + self.pe[: x.size(0), :]\n",
    "#     #     return x\n",
    "#     def forward(self, x):\n",
    "#         x = x + self.pe[:, :x.size(1)]\n",
    "#         return x\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        pe = torch.zeros(seq_len, self.d_model)\n",
    "        \n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / self.d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0).to(x.device)\n",
    "        x = x + pe\n",
    "        return x\n",
    "\n",
    "# Multi-Head Attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, nhead):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.nhead = nhead\n",
    "        self.head_dim = d_model // nhead\n",
    "        self.qkv_linear = nn.Linear(d_model, d_model * 3)\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        qkv = self.qkv_linear(x).view(batch_size, seq_len, self.nhead, -1).transpose(1, 2)\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        attn_output = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "        attn_output = torch.softmax(attn_output, dim=-1)\n",
    "        attn_output = torch.matmul(attn_output, v)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, -1)\n",
    "        attn_output = self.fc(attn_output)\n",
    "        return attn_output\n",
    "\n",
    "# Feedforward Network\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_model, dim_feedforward):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.fc2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# Transformer Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, nhead)\n",
    "        self.ffn = FeedForwardNetwork(d_model, dim_feedforward)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    def forward(self, x):\n",
    "        attn_output = self.mha(x)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.norm2(x + self.dropout(ffn_output))\n",
    "        return x\n",
    "\n",
    "# Transformer Model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers, dim_feedforward, max_seq_len):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        # self.pos_encoding = PositionalEncoding(d_model, max_seq_len)\n",
    "        self.pos_encoding = PositionalEncoding(d_model)\n",
    "        self.transformer_blocks = nn.ModuleList([TransformerBlock(d_model, nhead, dim_feedforward) for _ in range(num_layers)])\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "# class TransformerModel(nn.Module):\n",
    "#     def __init__(self, vocab_size, d_model, nhead, num_layers, dim_feedforward):\n",
    "#         super(TransformerModel, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "#         self.pos_encoding = PositionalEncoding(d_model)\n",
    "#         self.transformer_blocks = nn.ModuleList([TransformerBlock(d_model, nhead, dim_feedforward) for _ in range(num_layers)])\n",
    "#         self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.embedding(x)\n",
    "#         x = self.pos_encoding(x)\n",
    "#         for block in self.transformer_blocks:\n",
    "#             x = block(x)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "model = TransformerModel(vocab_size, d_model, nhead, num_layers, dim_feedforward, max_seq_len)\n",
    "# model = TransformerModel(vocab_size, d_model, nhead, num_layers, dim_feedforward)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Prepare input and target tensors\n",
    "input_data = torch.tensor(encoded_sentences[:-1], dtype=torch.long)\n",
    "target_data = torch.tensor(encoded_sentences[1:], dtype=torch.long)\n",
    "\n",
    "# Training\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_data)\n",
    "    loss = criterion(output.view(-1, vocab_size), target_data.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb0d5a",
   "metadata": {},
   "source": [
    "# ChachaGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c4e89eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: due have with transformed experienced AI stock AI due experienced AI stock AI due experienced AI decline decline decline decline AI decline decline decline decline decline decline AI\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "\n",
    "def generate_text(model, start_token, max_length):\n",
    "    model.eval()\n",
    "    generated_text = [start_token]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        input_data = torch.tensor([generated_text], dtype=torch.long)\n",
    "        output = model(input_data)\n",
    "        next_token_idx = torch.argmax(output[0, -1, :]).item()\n",
    "        generated_text.append(next_token_idx)\n",
    "\n",
    "        if idx2word[next_token_idx] == \"[SEP]\":\n",
    "            break\n",
    "\n",
    "    return \" \".join(idx2word[idx] for idx in generated_text if idx2word[idx] not in [\"[CLS]\", \"[SEP]\", \"[PAD]\"])\n",
    "\n",
    "# Randomly sample a starting token from the vocabulary\n",
    "random_start_token = random.choice(list(word2idx.values()))\n",
    "\n",
    "# Generate text\n",
    "generated_text = generate_text(model, random_start_token, max_length=30)\n",
    "print(\"Generated text:\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2759e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d43177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformer] *",
   "language": "python",
   "name": "conda-env-transformer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
